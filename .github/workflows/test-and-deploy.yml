name: Test and Conditional Deploy

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write
  actions: write

jobs:
  test-and-validate:
    runs-on: ubuntu-latest
    outputs:
      tests-passed: ${{ steps.test-results.outputs.passed }}
      overall-passed: ${{ steps.final-results.outputs.overall-passed }}
      lock-files-updated: ${{ steps.lock-check.outputs.updated }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Detect package manager
        id: detect-package-manager
        run: |
          if [ -f "${{ github.workspace }}/pnpm-lock.yaml" ]; then
            echo "manager=pnpm" >> $GITHUB_OUTPUT
            echo "command=install" >> $GITHUB_OUTPUT
            echo "runner=pnpm" >> $GITHUB_OUTPUT
            npm install -g pnpm
          elif [ -f "${{ github.workspace }}/yarn.lock" ]; then
            echo "manager=yarn" >> $GITHUB_OUTPUT
            echo "command=install" >> $GITHUB_OUTPUT
            echo "runner=yarn" >> $GITHUB_OUTPUT
          elif [ -f "${{ github.workspace }}/package.json" ]; then
            echo "manager=npm" >> $GITHUB_OUTPUT
            echo "command=ci" >> $GITHUB_OUTPUT
            echo "runner=npx --no-install" >> $GITHUB_OUTPUT
          else
            echo "Unable to determine package manager"
            exit 1
          fi

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "lts/*"
          cache: ${{ steps.detect-package-manager.outputs.manager }}

      - name: Check and update lock files
        id: lock-check
        run: |
          echo "Checking lock files currency..."
          LOCK_UPDATED=false
          
          # Store original lock file hashes
          if [ -f "package-lock.json" ]; then
            ORIGINAL_PACKAGE_LOCK=$(sha256sum package-lock.json)
          fi
          if [ -f "yarn.lock" ]; then
            ORIGINAL_YARN_LOCK=$(sha256sum yarn.lock)
          fi
          if [ -f "pnpm-lock.yaml" ]; then
            ORIGINAL_PNPM_LOCK=$(sha256sum pnpm-lock.yaml)
          fi
          
          # Install dependencies (this will update lock files if needed)
          ${{ steps.detect-package-manager.outputs.manager }} ${{ steps.detect-package-manager.outputs.command }}
          
          # Check if lock files were updated
          if [ -f "package-lock.json" ] && [ "$ORIGINAL_PACKAGE_LOCK" != "$(sha256sum package-lock.json)" ]; then
            echo "package-lock.json was updated"
            LOCK_UPDATED=true
          fi
          if [ -f "yarn.lock" ] && [ "$ORIGINAL_YARN_LOCK" != "$(sha256sum yarn.lock)" ]; then
            echo "yarn.lock was updated"
            LOCK_UPDATED=true
          fi
          if [ -f "pnpm-lock.yaml" ] && [ "$ORIGINAL_PNPM_LOCK" != "$(sha256sum pnpm-lock.yaml)" ]; then
            echo "pnpm-lock.yaml was updated"
            LOCK_UPDATED=true
          fi
          
          echo "updated=$LOCK_UPDATED" >> $GITHUB_OUTPUT
          
          # Commit updated lock files if any
          if [ "$LOCK_UPDATED" = "true" ]; then
            git config --local user.email "action@github.com"
            git config --local user.name "GitHub Action"
            git add *.lock package-lock.json yarn.lock pnpm-lock.yaml 2>/dev/null || true
            git commit -m "chore: update lock files" || true
            git push || true
          fi

      - name: Run comprehensive tests with all ESLint rules
        id: test-results
        run: |
          echo "Running comprehensive tests..."
          TEST_PASSED=true
          
          # Create temporary eslint config that enables all rules
          cat > .eslintrc.temp.js << 'EOF'
          module.exports = {
            extends: [
              'eslint:all',
              '@typescript-eslint/all',
              'next/core-web-vitals'
            ],
            parser: '@typescript-eslint/parser',
            parserOptions: {
              ecmaVersion: 'latest',
              sourceType: 'module',
              project: './tsconfig.json'
            },
            rules: {
              // Override only the most problematic rules that would break the build
              '@typescript-eslint/no-magic-numbers': 'warn',
              'no-magic-numbers': 'off',
              'one-var': 'off',
              'no-ternary': 'off',
              'max-lines-per-function': 'warn',
              'max-statements': 'warn',
              'id-length': 'warn'
            }
          };
          EOF
          
          # Run ESLint with comprehensive rules
          echo "Running ESLint with all rules enabled..."
          ${{ steps.detect-package-manager.outputs.runner }} eslint . --config .eslintrc.temp.js --ext .js,.jsx,.ts,.tsx --format json --output-file eslint-results.json || TEST_PASSED=false
          
          # Run TypeScript check
          echo "Running TypeScript check..."
          ${{ steps.detect-package-manager.outputs.runner }} tsc --noEmit || TEST_PASSED=false
          
          # Run Next.js build test
          echo "Running Next.js build test..."
          ${{ steps.detect-package-manager.outputs.runner }} next build || TEST_PASSED=false
          
          # Run any existing tests
          if [ -f "package.json" ] && grep -q '"test"' package.json; then
            echo "Running test suite..."
            ${{ steps.detect-package-manager.outputs.runner }} test || TEST_PASSED=false
          fi
          
          echo "passed=$TEST_PASSED" >> $GITHUB_OUTPUT
          
          # Clean up temp config
          rm -f .eslintrc.temp.js

      - name: Scan GitHub Actions workflows
        id: actions-scan
        run: |
          echo "Scanning GitHub Actions workflows for security and best practices..."
          ACTIONS_ISSUES_FOUND=false
          
          # Create GitHub Actions scan results file
          echo '[]' > github-actions-scan.json
          
          # Find all workflow files
          find .github/workflows -name "*.yml" -o -name "*.yaml" | while read -r workflow_file; do
            echo "Scanning: $workflow_file"
            
            # Check for security issues and best practices
            WORKFLOW_FILE="$workflow_file" python3 -c "
import yaml
import json
import sys
import os

workflow_file = os.environ.get('WORKFLOW_FILE', '')
issues = []

try:
    with open(workflow_file, 'r') as f:
        workflow = yaml.safe_load(f)
    
    # Check for security issues
    def check_workflow(data, path=''):
        if isinstance(data, dict):
            for key, value in data.items():
                current_path = f'{path}.{key}' if path else key
                
                # Check for hardcoded secrets
                if isinstance(value, str):
                    if any(secret in value.lower() for secret in ['password', 'token', 'key', 'secret']):
                        if not ('secrets.' in value or 'env.' in value):
                            issues.append({
                                'file': workflow_file,
                                'type': 'security',
                                'severity': 'high',
                                'rule': 'hardcoded-secrets',
                                'message': f'Potential hardcoded secret in {current_path}: {value[:50]}...',
                                'line': 0
                            })
                
                # Check for pinned action versions
                if key == 'uses' and isinstance(value, str):
                    if '@' not in value or value.endswith('@main') or value.endswith('@master'):
                        issues.append({
                            'file': workflow_file,
                            'type': 'security',
                            'severity': 'medium',
                            'rule': 'unpinned-action',
                            'message': f'Action not pinned to specific version: {value}',
                            'line': 0
                        })
                
                # Check for overly broad permissions
                if key == 'permissions' and isinstance(value, dict):
                    if 'contents' in value and value['contents'] == 'write':
                        if 'pages' not in value:
                            issues.append({
                                'file': workflow_file,
                                'type': 'security',
                                'severity': 'medium',
                                'rule': 'broad-permissions',
                                'message': 'Broad write permissions granted without specific need',
                                'line': 0
                            })
                
                # Check for shell injection risks
                if key == 'run' and isinstance(value, str):
                    if '\${{' in value and ('github.event' in value or 'github.head_ref' in value):
                        issues.append({
                            'file': workflow_file,
                            'type': 'security',
                            'severity': 'high',
                            'rule': 'shell-injection',
                            'message': 'Potential shell injection vulnerability in run command',
                            'line': 0
                        })
                
                check_workflow(value, current_path)
            
        elif isinstance(data, list):
            for i, item in enumerate(data):
                check_workflow(item, f'{path}[{i}]')
    
    check_workflow(workflow)
    
    # Load existing results and append
    try:
        with open('github-actions-scan.json', 'r') as f:
            existing_results = json.load(f)
    except:
        existing_results = []
    
    existing_results.extend(issues)
    
    with open('github-actions-scan.json', 'w') as f:
        json.dump(existing_results, f, indent=2)
    
    if issues:
        print(f'Found {len(issues)} issues in {workflow_file}')
        sys.exit(1)
    else:
        print(f'No issues found in {workflow_file}')
        
except Exception as e:
    print(f'Error scanning {workflow_file}: {e}')
    sys.exit(1)
" || ACTIONS_ISSUES_FOUND=true
          done
          
          # Install actionlint for additional checks
          echo "Installing actionlint..."
          curl -s https://raw.githubusercontent.com/rhymond/actionlint/main/scripts/download-actionlint.bash | bash
          
          # Run actionlint on all workflows
          echo "Running actionlint..."
          ./actionlint -format json .github/workflows/*.yml .github/workflows/*.yaml > actionlint-results.json 2>/dev/null || ACTIONS_ISSUES_FOUND=true
          
          # Merge actionlint results with our custom scan
          python3 -c "
import json

try:
    with open('actionlint-results.json', 'r') as f:
        actionlint_results = json.load(f)
except:
    actionlint_results = []

try:
    with open('github-actions-scan.json', 'r') as f:
        custom_results = json.load(f)
except:
    custom_results = []

# Convert actionlint format to our format
for issue in actionlint_results:
    custom_results.append({
        'file': issue.get('filepath', 'unknown'),
        'type': 'actionlint',
        'severity': 'medium',
        'rule': issue.get('kind', 'unknown'),
        'message': issue.get('message', 'Unknown issue'),
        'line': issue.get('line', 0)
    })

with open('github-actions-scan.json', 'w') as f:
    json.dump(custom_results, f, indent=2)

print(f'Total GitHub Actions issues found: {len(custom_results)}')
"
          
          echo "actions-issues-found=$ACTIONS_ISSUES_FOUND" >> $GITHUB_OUTPUT

      - name: Combine all test results
        if: always()
        run: |
          echo "Combining all test results..."
          OVERALL_PASSED=true
          
          # Check if any tests failed
          if [ "${{ steps.test-results.outputs.passed }}" = "false" ]; then
            OVERALL_PASSED=false
          fi
          
          # Check if GitHub Actions scan found issues
          if [ "${{ steps.actions-scan.outputs.actions-issues-found }}" = "true" ]; then
            OVERALL_PASSED=false
          fi
          
          echo "overall-passed=$OVERALL_PASSED" >> $GITHUB_OUTPUT
        id: final-results

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            eslint-results.json
            github-actions-scan.json
            actionlint-results.json
            .next/
          retention-days: 7

  deploy-on-success:
    needs: test-and-validate
    if: needs.test-and-validate.outputs.overall-passed == 'true'
    uses: ./.github/workflows/deploy.yml
    secrets: inherit

  generate-report-on-failure:
    needs: test-and-validate
    if: needs.test-and-validate.outputs.overall-passed == 'false'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download test artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: ./test-results

      - name: Generate CSV report
        run: |
          echo "Creating test failure report..."
          
          # Create reports directory
          mkdir -p reports
          
          # Generate CSV header
          echo "Timestamp,Test Type,File,Line,Column,Severity,Rule,Message" > reports/test-failures.csv
          
          # Process ESLint results if available
          if [ -f "test-results/eslint-results.json" ]; then
            echo "Processing ESLint results..."
            node -e "
              const fs = require('fs');
              try {
                const results = JSON.parse(fs.readFileSync('test-results/eslint-results.json', 'utf8'));
                const timestamp = new Date().toISOString();
                
                results.forEach(file => {
                  file.messages.forEach(msg => {
                    const row = [
                      timestamp,
                      'ESLint',
                      file.filePath.replace(process.cwd() + '/', ''),
                      msg.line || 0,
                      msg.column || 0,
                      msg.severity === 2 ? 'error' : 'warning',
                      msg.ruleId || 'unknown',
                      '\"' + (msg.message || '').replace(/\"/g, '\"\"') + '\"'
                    ];
                    console.log(row.join(','));
                  });
                });
              } catch (e) {
                console.error('Error processing ESLint results:', e.message);
              }
            " >> reports/test-failures.csv
          fi
          
          # Process GitHub Actions scan results if available
          if [ -f "test-results/github-actions-scan.json" ]; then
            echo "Processing GitHub Actions scan results..."
            node -e "
              const fs = require('fs');
              try {
                const results = JSON.parse(fs.readFileSync('test-results/github-actions-scan.json', 'utf8'));
                const timestamp = new Date().toISOString();
                
                results.forEach(issue => {
                  const row = [
                    timestamp,
                    'GitHub Actions',
                    issue.file.replace(process.cwd() + '/', ''),
                    issue.line || 0,
                    0,
                    issue.severity || 'warning',
                    issue.rule || 'unknown',
                    '\"' + (issue.message || '').replace(/\"/g, '\"\"') + '\"'
                  ];
                  console.log(row.join(','));
                });
              } catch (e) {
                console.error('Error processing GitHub Actions scan results:', e.message);
              }
            " >> reports/test-failures.csv
          fi
          
          # Add build failures if any
          echo "$(date -Iseconds),Build,N/A,0,0,error,build-failure,\"Build process failed\"" >> reports/test-failures.csv
          
          echo "Report generated with $(wc -l < reports/test-failures.csv) entries"

      - name: Create mdBook structure
        run: |
          # Create mdBook directory structure
          mkdir -p docs/src
          
          # Create book.toml
          cat > docs/book.toml << 'EOF'
          [book]
          authors = ["GitHub Actions"]
          language = "en"
          multilingual = false
          src = "src"
          title = "Test Failure Report"
          
          [output.html]
          default-theme = "navy"
          preferred-dark-theme = "navy"
          
          [output.html.print]
          enable = true
          EOF
          
          # Create SUMMARY.md
          cat > docs/src/SUMMARY.md << 'EOF'
          # Summary
          
          - [Test Failure Report](./report.md)
          - [Raw CSV Data](./csv-data.md)
          EOF
          
          # Convert CSV to markdown table
          cat > docs/src/report.md << 'EOF'
          # Test Failure Report
          
          This report was generated automatically when tests failed.
          
          ## Summary
          
          EOF
          
          # Add summary statistics
          TOTAL_ISSUES=$(tail -n +2 reports/test-failures.csv | wc -l)
          ESLINT_ISSUES=$(grep "ESLint" reports/test-failures.csv | wc -l)
          ACTIONS_ISSUES=$(grep "GitHub Actions" reports/test-failures.csv | wc -l)
          BUILD_ISSUES=$(grep "Build" reports/test-failures.csv | wc -l)
          
          cat >> docs/src/report.md << EOF
          - **Total Issues**: $TOTAL_ISSUES
          - **ESLint Issues**: $ESLINT_ISSUES
          - **GitHub Actions Issues**: $ACTIONS_ISSUES
          - **Build Issues**: $BUILD_ISSUES
          - **Generated**: $(date)
          
          ## Issues Detail
          
          | Test Type | File | Line | Severity | Rule | Message |
          |-----------|------|------|----------|------|---------|
          EOF
          
          # Convert CSV to markdown table (skip header and timestamp/column)
          tail -n +2 reports/test-failures.csv | while IFS=',' read -r timestamp testtype file line column severity rule message; do
            echo "| $testtype | $file | $line | $severity | $rule | $message |" >> docs/src/report.md
          done
          
          # Create raw CSV data page
          cat > docs/src/csv-data.md << 'EOF'
          # Raw CSV Data
          
          ```csv
          EOF
          cat reports/test-failures.csv >> docs/src/csv-data.md
          echo '```' >> docs/src/csv-data.md

      - name: Setup mdBook
        uses: peaceiris/actions-mdbook@v1
        with:
          mdbook-version: 'latest'

      - name: Build mdBook
        run: |
          cd docs
          mdbook build

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs/book
          destination_dir: test-reports

      - name: Comment on PR with report link
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const reportUrl = `https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/test-reports/`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ‚ùå Tests Failed\n\nA detailed test failure report has been generated and published:\n\nüîó **[View Test Report](${reportUrl})**\n\nPlease review the issues and fix them before merging.`
            });